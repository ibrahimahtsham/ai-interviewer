What it is

A local Streamlit app that acts like an “AI interviewer”. I speak, it transcribes (STT), sends the transcript to a local LLM for an interviewer-style reply, then speaks the reply back (TTS). English only.

How I want it deployed (local-only)

- Single Streamlit app the user runs locally with a simple command.
- Everything runs on the user’s machine (no GitHub Pages, no cloud).
- No CORS/TLS complexity needed because UI and logic are in one app.

How it should work (PoC)

- Start/Stop button to record my whole answer in one go (microphone capture in the browser).
- When I press Stop, the app runs STT → gets transcript (English only).
- Feed transcript to LLM with a system prompt like: “You are an interviewer for X person for Y job. Always respond in English.”
- Take the LLM reply and run TTS (English voice).
- Play the audio reply and also show the text on screen.

Controls in the UI

- Choose STT model size (lighter vs heavier for CPU/GPU).
- Choose LLM model (from local models installed in Ollama).
- Choose TTS voice (English voices).
- These choices should affect what actually runs.

English-only behavior

- STT runs with language set to English (no auto-detect, no translation).
- LLM receives a system rule to respond only in English.
- TTS uses an English voice (en_US or en_GB, etc.).

Tools & technologies (concise)

- Python 3.10+
- Streamlit (UI)
- Microphone capture: one of
	- streamlit-webrtc (stable, supports recording/playback), or
	- streamlit-mic-recorder (simple voice capture component)
- STT: faster-whisper (CTranslate2) + ffmpeg
- LLM: Ollama (local models like llama3, mistral, qwen2.5, phi4)
- TTS: piper-tts with English voices (fast, offline)
- Optional: CUDA for GPU acceleration (faster-whisper and Ollama can use GPU)

Goal

- Anyone can clone the repo and run the Streamlit app locally for free on their own computer.
- The app records, transcribes, generates an interviewer response, and speaks it back in English, with simple model/voice controls.

